from langchain_mcp_adapters.client import MultiServerMCPClient
from agent import build_simple_agent
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.checkpoint.memory import MemorySaver
import asyncio
import warnings
from prompt import PUBMED_PROMPT
from mcp_client_config import client_config
warnings.filterwarnings("ignore", category=UserWarning)

async def get_multiline_input(prompt: str) -> str:
    print(f"{prompt} (ì „ì†¡: ë¹ˆ ì¤„ì—ì„œ Enter ì…ë ¥)")
    lines = []
    
    while True:
        # ê° ì¤„ì„ ë°›ì„ ë•ŒëŠ” strip()ì„ í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ë°›ìŒ
        line = await asyncio.to_thread(input, "> ")
        
        # ì‚¬ìš©ìê°€ ì•„ë¬´ê²ƒë„ ì¹˜ì§€ ì•Šê³  ì—”í„°ë§Œ ëˆŒë €ì„ ë•Œ (ì§„ì§œ ë¹ˆ ì¤„)
        if line == "": 
            break
        
        lines.append(line)
    
    # ëª¨ë“  ì¤„ì„ í•©ì¹œ í›„, ì „ì²´ ë©”ì‹œì§€ì˜ ì•ë’¤ ê³µë°±ë§Œ ë”± í•œ ë²ˆ ì œê±°
    return "\n".join(lines).strip()

async def run_pubmed():

    # Memory Configuration
    memory = MemorySaver()
    config = {"configurable": {"thread_id": "thread_1"}}

    # MCP Server Connection
    try:
        print("CONNECTING MCP SERVER...")
        client = MultiServerMCPClient(client_config)
        # ì´ ë‹¨ê³„ì—ì„œ ì„œë²„ê°€ ì•ˆ ëœ¨ë©´ ë¬´í•œ ëŒ€ê¸°í•˜ê±°ë‚˜ ì£½ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        tools = await asyncio.wait_for(client.get_tools(), timeout=120.0) 
    except asyncio.TimeoutError:
        print("âŒ MCP ì„œë²„ ì—°ê²° íƒ€ì„ì•„ì›ƒ!")
        return
    except Exception as e:
        print(f"âŒ ì—°ê²° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return

    if not tools:
        print("âŒ MCP ë„êµ¬ë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… Loaded {len(tools)} tools.")
    
    # Agent Initialization
    pubmed_agent = build_simple_agent(
        model="gpt-5-nano",
        system_prompt=PUBMED_PROMPT,
        tools=tools,
        checkpointer=memory
    )

    print("\n--- PubMed AI Agent Started ---")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit'ì„ ì…ë ¥í•˜ì„¸ìš”.")

    # 2. ë°˜ë³µ ë£¨í”„ ì‹œì‘
    while True:
        user_input = await get_multiline_input("\n[User]: ")

        if user_input.lower() in ["exit", "quit"]:
            print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if not user_input:
            continue

        msg = {
            "messages": [HumanMessage(content=user_input)]
        }

        try:
            print("ğŸ¤– ...", end="\n", flush=True)
            
            # stream_mode="messages"ëŠ” ëª¨ë¸ì´ ë±‰ëŠ” í† í° í•˜ë‚˜í•˜ë‚˜ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
            async for chunk, metadata in pubmed_agent.astream(
                msg, 
                config=config, 
                stream_mode="messages"
            ):
                # 1. AI ë©”ì‹œì§€ì´ê³ , ë‹µë³€ ë‚´ìš©(content)ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶œë ¥
                if isinstance(chunk, AIMessage) and chunk.content:
                    # ì‹¤ì‹œê°„ìœ¼ë¡œ í•œ ê¸€ìì”©/í•œ ë¬¸ì¥ì”© ì¶œë ¥ (ì¤„ë°”ê¿ˆ ì—†ì´)
                    print(chunk.content, end="", flush=True)
            
            print("\n" + "="*50)
            
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    try:
        asyncio.run(run_pubmed())
    except KeyboardInterrupt:
        print("\nê°•ì œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")