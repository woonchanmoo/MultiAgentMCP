from langchain_mcp_adapters.client import MultiServerMCPClient
from agent import build_simple_agent
from langchain_core.messages import HumanMessage, AIMessageChunk, RemoveMessage
from langgraph.checkpoint.memory import MemorySaver
import asyncio
import warnings
from prompt import BASE_SYSTEM_PROMPT
from config.config import MCP_CONFIG, MCP_FILESYSTEM_DIR
from prompt_toolkit import prompt as pt_prompt

warnings.filterwarnings("ignore", category=UserWarning)

async def get_multiline_input(prompt: str) -> str:
    print(prompt)
    # multiline=Trueì¼ ë•Œ, ì „ì†¡ì€ ë³´í†µ 'Esc' ëˆ„ë¥¸ í›„ 'Enter' ë˜ëŠ” 'Meta+Enter'
    # í˜¹ì€ ë§ˆìš°ìŠ¤ë¡œ í´ë¦­í•  ìˆ˜ ì—†ëŠ” í™˜ê²½ì´ë¯€ë¡œ ì•ˆë‚´ ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    user_input = await asyncio.to_thread(
        pt_prompt, 
        "> ", 
        multiline=True,
        prompt_continuation="  " # ì¤„ë°”ê¿ˆ ì‹œ ì•ì— ë¶™ëŠ” ì ‘ë‘ì–´
    )
    return user_input.strip()

async def stream_graph_response(input, graph, config={}):
    async for message_chunk, metadata in graph.astream(
        input=input, stream_mode="messages", config=config
    ):
        # 1. ë…¸ë“œ ì´ë¦„ì„ ëª°ë¼ë„, Agent ë…¸ë“œì—ì„œ ì˜¤ëŠ” ê²ƒë§Œ í•„í„°ë§ (ê°€ì¥ ì•ˆì „)
        if metadata.get("langgraph_node") == "tools":
            continue

        if isinstance(message_chunk, AIMessageChunk):
            # ë„êµ¬ í˜¸ì¶œ ì™„ë£Œ ì‹œ ì¤„ë°”ê¿ˆ
            if message_chunk.response_metadata.get("finish_reason") == "tool_calls":
                yield "\n\n"

            if message_chunk.tool_call_chunks:
                tool_chunk = message_chunk.tool_call_chunks[0]
                
                # 2. tool_nameê³¼ argsë¥¼ 'ëˆ„ì 'í•´ì„œ ì¶œë ¥í•˜ë„ë¡ ìˆ˜ì •
                if tool_chunk.get("name"):
                    yield f"\033[94m > Tool used: {tool_chunk['name']} \033[0m\n"
                if tool_chunk.get("args"):
                    yield f"\033[90m{tool_chunk['args']}\033[0m\n"  # ë®ì–´ì“°ì§€ ì•Šê³  ì´ì–´ì„œ ë³´ëƒ„
            else:
                yield message_chunk.content

async def fix_memory_if_broken(graph, config):
    state = await graph.aget_state(config)
    if not state.values or "messages" not in state.values:
        return False

    messages = state.values["messages"]
    if len(messages) < 2: return False

    # ì‚­ì œí•  ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„
    to_remove = []
    
    # 1. ë§ˆì§€ë§‰ AIì˜ ì˜ëª»ëœ ë„êµ¬ í˜¸ì¶œ ì‚­ì œ
    last_msg = messages[-1]
    if hasattr(last_msg, "tool_calls") and last_msg.tool_calls:
        to_remove.append(RemoveMessage(id=last_msg.id))
        
        # 2. [ì¶”ê°€] ê·¸ ì›ì¸ì´ ëœ ë°”ë¡œ ì§ì „ì˜ Human ë©”ì‹œì§€ë„ í•¨ê»˜ ì‚­ì œ
        prev_msg = messages[-2]
        if isinstance(prev_msg, HumanMessage):
            print(f"ğŸ§¹ ì›ì¸ì´ ëœ ì‚¬ìš©ì ìš”ì²­ë„ í•¨ê»˜ ì •ë¦¬í•©ë‹ˆë‹¤: '{prev_msg.content[:20]}...'")
            to_remove.append(RemoveMessage(id=prev_msg.id))

    if to_remove:
        await graph.aupdate_state(config, {"messages": to_remove})
        return True
    return False

async def run_mcp_agent():

    # Memory Configuration
    memory = MemorySaver()
    config = {"configurable": {"thread_id": "thread_1"}}

    # MCP Server Connection
    try:
        print("CONNECTING MCP SERVER...")
        client = MultiServerMCPClient(MCP_CONFIG)
        # ì´ ë‹¨ê³„ì—ì„œ ì„œë²„ê°€ ì•ˆ ëœ¨ë©´ ë¬´í•œ ëŒ€ê¸°í•˜ê±°ë‚˜ ì£½ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        tools = await asyncio.wait_for(client.get_tools(), timeout=120.0) 
    except asyncio.TimeoutError:
        print("âŒ MCP ì„œë²„ ì—°ê²° íƒ€ì„ì•„ì›ƒ!")
        return
    except Exception as e:
        print(f"âŒ ì—°ê²° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return

    if not tools:
        print("âŒ MCP ë„êµ¬ë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… Loaded {len(tools)} tools.")

    system_prompt = f"""
    Your name is Scout and you are an expert data scientist. You help customers manage their data science projects by leveraging the tools available to you. Your goal is to collaborate with the customer in incrementally building their analysis or data modeling project. Version control is a critical aspect of this project, so you must use the git tools to manage the project's version history and maintain a clean, easy to understand commit history.

    <filesystem>
    You have access to a set of tools that allow you to interact with the user's local filesystem. 
    You are only able to access files within the working directory `projects`. 
    The absolute path to this directory is: {MCP_FILESYSTEM_DIR}
    If you try to access a file outside of this directory, you will receive an error.
    Always use absolute paths when specifying files.
    </filesystem>

    {BASE_SYSTEM_PROMPT}

    <tools>
    {tools}
    </tools>

    Assist the customer in all aspects of their data science workflow.
    """
    
    # Agent Initialization
    mcp_agent = build_simple_agent(
        model="gpt-5-nano",
        system_prompt=system_prompt,
        tools=tools,
        checkpointer=memory
    )

    print("\n--- PubMed AI Agent Started ---")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit'ì„ ì…ë ¥í•˜ì„¸ìš”. (esc + Enter ë¡œ ì…ë ¥)")

    # 2. ë°˜ë³µ ë£¨í”„ ì‹œì‘
    while True:
        user_input = await get_multiline_input("\n[User]: ")

        if user_input.lower() in ["exit", "quit"]:
            print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if not user_input:
            continue

        msg = {
            "messages": [HumanMessage(content=user_input)]
        }

        try:
            print("ğŸ¤– ...", end="\n", flush=True)
            
            # í†µí•©ëœ ì œë„ˆë ˆì´í„° í˜¸ì¶œ
            async for text in stream_graph_response(msg, mcp_agent, config):
                print(text, end="", flush=True)
            
            print("\n" + "="*50)
            
        except Exception as e:
            # ë³€ìˆ˜ë¥¼ ë¯¸ë¦¬ ì´ˆê¸°í™”í•´ë‘¡ë‹ˆë‹¤.
            was_fixed = False
            
            # 1. ë„êµ¬ í˜¸ì¶œ ë©”ì‹œì§€ì™€ ê²°ê³¼ê°€ ì§ì´ ì•ˆ ë§ì„ ë•Œ (400 ì—ëŸ¬ ë“±)
            if "tool_calls" in str(e) or "ToolException" in str(type(e).__name__):
                print(f"\n\033[93mğŸ› ï¸  ì˜¤ë¥˜ ê°ì§€({type(e).__name__}): ë©”ëª¨ë¦¬ ë³µêµ¬ ì‹œë„...\033[0m")
                was_fixed = await fix_memory_if_broken(mcp_agent, config)
                
                if was_fixed:
                    print("\033[92mâœ… ë³µêµ¬ ì™„ë£Œ! ì´ì „ ì—ëŸ¬ ë©”ì‹œì§€ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.\033[0m")
                    print("\033[94mğŸ’¡ íŒ: ë‹¤ë¥¸ ëª…ë ¹ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\033[0m")
                    # ğŸ’¡ [í•µì‹¬] ì—¬ê¸°ì„œ ë‹¤ì‹œ ì‹œë„í•˜ì§€ ì•Šê³  'continue'ë¥¼ í†µí•´ ë£¨í”„ì˜ ì²˜ìŒ(input ë‹¨ê³„)ìœ¼ë¡œ ì í”„!
                    continue
                else:
                    print("\nâŒ ìë™ ë³µêµ¬ê°€ ë¶ˆê°€ëŠ¥í•œ ìƒíƒœì…ë‹ˆë‹¤.")
            else:
                # ë³´ì•ˆ ìœ„ë°˜ ë“± ë„êµ¬ ìì²´ì˜ ì—ëŸ¬ì¸ ê²½ìš°
                print(f"\nâŒ ì‹¤í–‰ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    # í„°ë¯¸ë„ ì‹¤í–‰ ì‹œì—ëŠ” ì•„ë˜ ë‘ ì¤„ì´ ì—†ì–´ë„ ë˜ì§€ë§Œ, ë…¸íŠ¸ë¶ í™˜ê²½ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ ê°€ëŠ¥
    import nest_asyncio
    nest_asyncio.apply()

    try:
        # ìš°ë¦¬ê°€ ë§Œë“  ë¹„ë™ê¸° ì—ì´ì „íŠ¸ ì‹¤í–‰ ë£¨í”„
        asyncio.run(run_mcp_agent())
    except KeyboardInterrupt:
        print("\nê°•ì œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")