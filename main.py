from langchain_mcp_adapters.client import MultiServerMCPClient
from agent import build_simple_agent
from langchain_core.messages import HumanMessage, AIMessageChunk, RemoveMessage
from langgraph.checkpoint.memory import MemorySaver
import asyncio
import warnings
from prompt import BASE_SYSTEM_PROMPT
from config.config import MCP_CONFIG, MCP_FILESYSTEM_DIR
from prompt_toolkit import prompt as pt_prompt

warnings.filterwarnings("ignore", category=UserWarning)

async def get_multiline_input(prompt: str) -> str:
    # \033[96m: Cyanìƒ‰, \033[1m: Bold, \033[0m: Reset
    guide = "\033[96m\033[1m(ì „ì†¡: Esc ëˆ„ë¥¸ í›„ Enter)\033[0m"
    print(f"{prompt} {guide}")
    # multiline=Trueì¼ ë•Œ, ì „ì†¡ì€ ë³´í†µ 'Esc' ëˆ„ë¥¸ í›„ 'Enter' ë˜ëŠ” 'Meta+Enter'
    # í˜¹ì€ ë§ˆìš°ìŠ¤ë¡œ í´ë¦­í•  ìˆ˜ ì—†ëŠ” í™˜ê²½ì´ë¯€ë¡œ ì•ˆë‚´ ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    user_input = await asyncio.to_thread(
        pt_prompt, 
        "> ", 
        multiline=True,
        prompt_continuation="  " # ì¤„ë°”ê¿ˆ ì‹œ ì•ì— ë¶™ëŠ” ì ‘ë‘ì–´
    )
    return user_input.strip()

async def stream_graph_response(input, graph, config={}):
    current_tool_args = ""
    last_index = -1  # í˜„ì¬ ì¶œë ¥ ì¤‘ì¸ ë„êµ¬ì˜ ì¸ë±ìŠ¤ë¥¼ ì¶”ì 
    
    yield "\033[1;32m[AI]:\033[0m "

    async for message_chunk, metadata in graph.astream(
        input=input, stream_mode="messages", config=config
    ):
        if metadata.get("langgraph_node") == "tools":
            continue

        if isinstance(message_chunk, AIMessageChunk):
            # 1. ë„êµ¬ í˜¸ì¶œ ì‹œì‘/ì§„í–‰ ì¤‘
            if message_chunk.tool_call_chunks:
                for chunk in message_chunk.tool_call_chunks:
                    idx = chunk.get("index")
                    
                    # ğŸ’¡ í•µì‹¬: ìƒˆë¡œìš´ ì¸ë±ìŠ¤ê°€ ë“±ì¥í•  ë•Œë§Œ ì´ë¦„ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
                    if idx != last_index:
                        if chunk.get("name"):
                            yield f"\n\n\033[94mğŸ› ï¸  Executing Tool: {chunk['name']}\033[0m\n"
                            last_index = idx  # ì¶œë ¥í•œ ë„êµ¬ì˜ ì¸ë±ìŠ¤ë¥¼ ì €ì¥
                    
                    # ì¸ì(args)ëŠ” ë“¤ì–´ì˜¤ëŠ” ëŒ€ë¡œ ë°”ë¡œ ì¶œë ¥ (íšŒìƒ‰)
                    if chunk.get("args"):
                        yield f"\033[90m{chunk['args']}\033[0m"
                        # ë‚˜ì¤‘ì— ì •ë ¬ëœ ì¶œë ¥ì„ ì›í•œë‹¤ë©´ ì—¬ê¸°ì— ëˆ„ì ë§Œ í•˜ì„¸ìš”.
                        current_tool_args += chunk["args"]
            
            # 2. ì¼ë°˜ í…ìŠ¤íŠ¸ ë‚´ìš© ì¶œë ¥
            elif message_chunk.content:
                yield message_chunk.content

            # 3. ë§ˆë¬´ë¦¬ (í•„ìš” ì‹œ)
            if message_chunk.response_metadata.get("finish_reason") == "tool_calls":
                yield "\n"
                last_index = -1 # ì´ˆê¸°í™”

async def fix_memory_if_broken(graph, config, error_type=None):
    state = await graph.aget_state(config)
    if not state.values or "messages" not in state.values:
        return False

    messages = state.values["messages"]
    if not messages: return False
    
    to_remove = []

    # 1. íŠ¹ì • ì—ëŸ¬(Recursion)ì¸ ê²½ìš°: HumanMessageê¹Œì§€ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°€ë©° ì „ì²´ ì‚­ì œ
    if error_type == "RecursionError":
        print("ğŸ”„ ë‹¨ê³„ ì´ˆê³¼: ê´€ë ¨ ë¬¸ë§¥ì„ ëª¨ë‘ ì •ë¦¬í•©ë‹ˆë‹¤.")
        for msg in reversed(messages):
            to_remove.append(RemoveMessage(id=msg.id))
            if isinstance(msg, HumanMessage): 
                break 

    # 2. ê·¸ ì™¸ ëª¨ë“  ì—ëŸ¬ (ë„êµ¬ ì—ëŸ¬, API ì—ëŸ¬, ì¼ë°˜ ì˜ˆì™¸ ë“±)
    else:
        # ê°€ì¥ ë§ˆì§€ë§‰ ë©”ì‹œì§€ë¶€í„° ì§€ìš°ë˜, HumanMessageë¥¼ ë§Œë‚  ë•Œê¹Œì§€ ì§€ì›ë‹ˆë‹¤.
        # ì´ë ‡ê²Œ í•˜ë©´ 'ì˜ëª»ëœ ë„êµ¬ í˜¸ì¶œ AI ë©”ì‹œì§€'ì™€ 'ì›ì¸ì´ ëœ ì‚¬ìš©ì ì§ˆë¬¸'ì´ ëª¨ë‘ ì‚­ì œë©ë‹ˆë‹¤.
        for msg in reversed(messages):
            to_remove.append(RemoveMessage(id=msg.id))
            if isinstance(msg, HumanMessage):
                break

    if to_remove:
        await graph.aupdate_state(config, {"messages": to_remove}, as_node="Agent")
        return True
    return False

async def run_mcp_agent():

    # Memory Configuration
    memory = MemorySaver()
    config = {
        "configurable": {"thread_id": "thread_1"},
        "recursion_limit": 100} # 50ë²ˆ ì´ìƒì˜ ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥

    # MCP Server Connection
    try:
        print("CONNECTING MCP SERVER...")
        client = MultiServerMCPClient(MCP_CONFIG)
        # ì´ ë‹¨ê³„ì—ì„œ ì„œë²„ê°€ ì•ˆ ëœ¨ë©´ ë¬´í•œ ëŒ€ê¸°í•˜ê±°ë‚˜ ì£½ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        tools = await asyncio.wait_for(client.get_tools(), timeout=120.0) 
    except asyncio.TimeoutError:
        print("âŒ MCP ì„œë²„ ì—°ê²° íƒ€ì„ì•„ì›ƒ!")
        return
    except Exception as e:
        print(f"âŒ ì—°ê²° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return

    if not tools:
        print("âŒ MCP ë„êµ¬ë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… Loaded {len(tools)} tools.")

    system_prompt = f"""
    Your name is Scout and you are an expert data scientist. You help customers manage their data science projects by leveraging the tools available to you. Your goal is to collaborate with the customer in incrementally building their analysis or data modeling project. Version control is a critical aspect of this project, so you must use the git tools to manage the project's version history and maintain a clean, easy to understand commit history.

    <filesystem>
    You have access to a set of tools that allow you to interact with the user's local filesystem. 
    You are only able to access files within the working directory `projects`. 
    The absolute path to this directory is: {MCP_FILESYSTEM_DIR}
    If you try to access a file outside of this directory, you will receive an error.
    Always use absolute paths when specifying files.
    </filesystem>

    {BASE_SYSTEM_PROMPT}

    <tools>
    {tools}
    </tools>

    Assist the customer in all aspects of their data science workflow.
    """
    
    # Agent Initialization
    mcp_agent = build_simple_agent(
        model="gpt-5-nano",
        system_prompt=system_prompt,
        tools=tools,
        checkpointer=memory
    )

    print("\n--- PubMed AI Agent Started ---")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit'ì„ ì…ë ¥í•˜ì„¸ìš”.")

    # 2. ë°˜ë³µ ë£¨í”„ ì‹œì‘
    while True:
        user_input = await get_multiline_input("\n[User]: ")

        if user_input.lower() in ["exit", "quit"]:
            print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if not user_input:
            continue

        msg = {
            "messages": [HumanMessage(content=user_input)]
        }

        try:
            print("\nğŸ¤– ...", end="\n\n", flush=True)
            
            # í†µí•©ëœ ì œë„ˆë ˆì´í„° í˜¸ì¶œ
            async for text in stream_graph_response(msg, mcp_agent, config):
                print(text, end="", flush=True)
            
            print("\n" + "="*50)
            
        except Exception as e:
                    error_str = str(e)
                    error_name = type(e).__name__
                    
                    # [ìˆ˜ì •] ì–´ë–¤ ì—ëŸ¬ê°€ ë°œìƒí•˜ë“  ë©”ëª¨ë¦¬ ë³µêµ¬ë¥¼ ì‹œë„í•˜ë„ë¡ í†µí•©
                    print(f"\n\033[91mâŒ ì˜¤ë¥˜ ë°œìƒ ({error_name}): ë©”ëª¨ë¦¬ë¥¼ ì •ë¦¬í•˜ê³  ë³µêµ¬ë¥¼ ì‹œë„í•©ë‹ˆë‹¤...\033[0m")
                    
                    # ì—ëŸ¬ ì¢…ë¥˜ì— ë”°ë¥¸ íƒ€ì… ì§€ì •
                    e_type = "RecursionError" if "Recursion limit" in error_str else "GeneralError"
                    
                    was_fixed = await fix_memory_if_broken(mcp_agent, config, error_type=e_type)
                    
                    if was_fixed:
                        print("\033[92mâœ… ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ. ë‹¤ìŒ ì§ˆë¬¸ì„ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\033[0m")
                        # ğŸ’¡ continueë¥¼ í•˜ë©´ ë£¨í”„ì˜ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ ìƒˆë¡œìš´ ì…ë ¥ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
                        continue
                    else:
                        print("\033[93mâš ï¸ ë©”ëª¨ë¦¬ë¥¼ ì •ë¦¬í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.\033[0m")

if __name__ == "__main__":
    # í„°ë¯¸ë„ ì‹¤í–‰ ì‹œì—ëŠ” ì•„ë˜ ë‘ ì¤„ì´ ì—†ì–´ë„ ë˜ì§€ë§Œ, ë…¸íŠ¸ë¶ í™˜ê²½ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ ê°€ëŠ¥
    import nest_asyncio
    nest_asyncio.apply()

    try:
        # ìš°ë¦¬ê°€ ë§Œë“  ë¹„ë™ê¸° ì—ì´ì „íŠ¸ ì‹¤í–‰ ë£¨í”„
        asyncio.run(run_mcp_agent())
    except KeyboardInterrupt:
        print("\nê°•ì œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")