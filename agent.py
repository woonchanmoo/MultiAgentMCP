from langgraph.graph import StateGraph, START, END
from langchain.chat_models import init_chat_model
from langgraph.prebuilt import ToolNode, tools_condition
from typing import Annotated, TypedDict, Any, Sequence
from langchain_core.messages import BaseMessage, AIMessage, ToolMessage, HumanMessage
from langgraph.graph.message import add_messages
from dotenv import load_dotenv

load_dotenv()

# 1. ì‹¤ì œ ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•  í•¨ìˆ˜ ì •ì˜ (ì´ë¦„ì€ ììœ )
def handle_tool_error(error: Exception) -> str:
    print(f"--- [ğŸ”´ Tool Error Log ğŸ”´] ---\n{repr(error)}\n------------------------")
    return f"Error: {repr(error)}."

class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    error_count: int

def build_simple_agent(model: str, system_prompt: str, tools: Sequence[Any], checkpointer = None):
    llm = init_chat_model(model=model)
    llm_with_tools = llm.bind_tools(tools)

    async def agent_node(state: AgentState) -> AgentState:
        messages = state["messages"]
        current_errors = state.get("error_count", 0)

        # ğŸŒŸ [í•µì‹¬ ì¶”ê°€] ì‚¬ìš©ìê°€ ìƒˆë¡œìš´ ì…ë ¥ì„ í–ˆë‹¤ë©´ ì—ëŸ¬ ì¹´ìš´íŠ¸ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”
        # ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ HumanMessageë¼ë©´ ì‚¬ìš©ìê°€ ìƒˆë¡œìš´ ì‹œë„ë¥¼ í•˜ë ¤ëŠ” ê²ƒì´ë¯€ë¡œ ì¹´ìš´íŠ¸ë¥¼ ë¦¬ì…‹í•©ë‹ˆë‹¤.
        # 1. ìƒˆë¡œìš´ ì§ˆë¬¸ ì‹œ ì™„ì „ ì´ˆê¸°í™” í›„ ì¦‰ì‹œ ëª¨ë¸ í˜¸ì¶œë¡œ ì í”„
        if messages and isinstance(messages[-1], HumanMessage):
            current_errors = 0
            # ê³¼ê±° ì—ëŸ¬ ê³„ì‚° ë£¨í”„ë¥¼ íƒ€ì§€ ì•Šê³  ë°”ë¡œ ëª¨ë¸ í˜¸ì¶œë¡œ ë„˜ê¹ë‹ˆë‹¤.
            response = await llm_with_tools.ainvoke(messages)
            # (ë¡œê·¸ ì¶œë ¥ ë¡œì§ ìƒëµ)
            return {"messages": [response], "error_count": 0}

        # 2. íˆ´ ê²°ê³¼ì— ëŒ€í•œ ì—ëŸ¬ ê³„ì‚° (ì‚¬ìš©ì ì§ˆë¬¸ì´ ì•„ë‹ ë•Œë§Œ ì´ ì•„ë˜ê°€ ì‹¤í–‰ë¨)
        new_errors = 0
        for msg in reversed(messages):
            if isinstance(msg, ToolMessage):
                if "Error:" in msg.content:
                    new_errors += 1
            elif isinstance(msg, AIMessage) and msg.tool_calls:
                break

        if new_errors > 0:
            current_errors += new_errors
        else:
            # ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ ì„±ê³µí•œ íˆ´ ê²°ê³¼ë¼ë©´ ì´ˆê¸°í™”
            if messages and isinstance(messages[-1], ToolMessage):
                current_errors = 0

        # 3. ì„ê³„ì¹˜ ì²´í¬
        if current_errors >= 5:
            return {
                "messages": [AIMessage(content="ğŸ”´ ë‹¤ìˆ˜ì˜ ë„êµ¬ í˜¸ì¶œì—ì„œ ì—°ì†ì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")],
                "error_count": current_errors
            }
        
        # 4. ëª¨ë¸ í˜¸ì¶œ (íˆ´ ê²°ê³¼ë¥¼ ë³´ê³  ë‹¤ì‹œ íŒë‹¨í•´ì•¼ í•  ë•Œ)
        response = await llm_with_tools.ainvoke(messages)

        # # 4. ğŸ”¥ [ìµœì¢… ë¡œê·¸ í™•ì¸ ì˜ì—­] ğŸ”¥
        # print("\n\n" + "ğŸ“œ" + "="*30 + " FULL CONVERSATION LOG " + "="*30)
        # for i, msg in enumerate(messages + [response]):
        #     role = f"[{msg.type.upper()}]"
            
        #     # ë©”ì‹œì§€ ìœ í˜•ë³„ ìƒ‰ìƒ/ì´ë¦„ ì •ì˜ (í„°ë¯¸ë„ ê°€ë…ì„±)
        #     if isinstance(msg, HumanMessage):
        #         header = f"\033[92m{role} User:\033[0m" # ì´ˆë¡
        #     elif isinstance(msg, AIMessage):
        #         header = f"\033[94m{role} AI (Scout):\033[0m" # íŒŒë‘
        #     elif isinstance(msg, ToolMessage):
        #         header = f"\033[93m{role} Tool Result:\033[0m" # ë…¸ë‘
        #     else:
        #         header = role

        #     content = msg.content if msg.content else "(No text content)"
            
        #     # ë„êµ¬ í˜¸ì¶œ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€ ì¶œë ¥
        #     tool_info = ""
        #     if isinstance(msg, AIMessage) and msg.tool_calls:
        #         tool_info = f" ğŸ› ï¸ Calls: {[tc['name'] for tc in msg.tool_calls]}"

        #     print(f"{i:02d} {header}{tool_info}")
        #     # ë„ˆë¬´ ê¸¸ë©´ 150ìë§Œ ì¶œë ¥
        #     print(f"   Content: {str(content)[:150]}..." if len(str(content)) > 150 else f"   Content: {content}")
        # print(f"\nğŸ“Š Current Status - Error Count: {current_errors}")
        # print("="*85 + "\n")

        # ì—¬ê¸°ì„œ ì§ì ‘ printí•˜ì§€ ì•Šê³  responseë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
        return {
            "messages": [response],
            "error_count": current_errors}
    
    workflow = StateGraph(AgentState)

    tools_node = ToolNode(
    tools, 
    handle_tool_errors=handle_tool_error  # ì˜µì…˜ëª…=ì‹¤í–‰í• í•¨ìˆ˜
    )

    workflow.add_node("Agent", agent_node)
    workflow.add_node("tools", tools_node)
    workflow.add_edge(START, "Agent")
    workflow.add_conditional_edges(
        "Agent",
        tools_condition,
        {
            "tools": "tools",
            "__end__": END
        }
    )
    workflow.add_edge("tools", "Agent")

    return workflow.compile(checkpointer=checkpointer)
